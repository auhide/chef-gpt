import re
import logging

import streamlit as st
from transformers import AutoTokenizer, AutoModelForCausalLM

from config import MODEL_ID, TOKENIZER_PATH
from widgets import based_on_ingredients_widget, based_on_title_widget


st.set_page_config(
    page_title="ü§ñ –ò–∑–∫—É—Å—Ç–≤–µ–Ω –ì–æ—Ç–≤–∞—á",
)


# Hiding the default Streamlit hamburger and text.
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True) 


# When there has already been a defined logger in the environment.
if len(logging.getLogger().handlers) > 0:
    logging.getLogger().setLevel(logging.INFO)
else:
    logging.basicConfig(
        format="%(asctime)s|%(levelname)s:\t%(message)s",
        level=logging.INFO,
        datefmt="%m/%d/%Y %I:%M:%S %p"
    )


@st.cache_resource(show_spinner=False)
def _get_model():
    return AutoModelForCausalLM.from_pretrained(MODEL_ID)


@st.cache_resource(show_spinner=False)
def _get_tokenizer():
    return AutoTokenizer.from_pretrained(TOKENIZER_PATH)


with st.spinner("–ì–æ—Ç–≤–∞—á—ä—Ç —Å–µ –ø—Ä–∏–≥–æ—Ç–≤—è..."):
    chef_gpt = _get_model()

with st.spinner("–ì–æ—Ç–≤–∞—á—ä—Ç –æ–ø—Ä–µ—Å–Ω—è–≤–∞ –∑–Ω–∞–Ω–∏—è—Ç–∞ —Å–∏..."):
    tokenizer = _get_tokenizer()


st.markdown("<h1 style='text-align: center; color: grey;'>–ò–∑–∫—É—Å—Ç–≤–µ–Ω –ì–æ—Ç–≤–∞—á</h1>", unsafe_allow_html=True)
st.caption("–í—ä–≤–µ–∂–¥–∞–Ω–µ—Ç–æ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç–∏—Ç–µ –ø–æ–º–∞–≥–∞ –Ω–∞ –ì–æ—Ç–≤–∞—á–∞. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤–º–µ—Å—Ç–æ '–±—Ä–∞—à–Ω–æ' - '1 —á.—á. –±—Ä–∞—à–Ω–æ' –∏–ª–∏ '250 –≥—Ä –±—Ä–∞—à–Ω–æ'. –í—Å–µ –ø–∞–∫ –ì–æ—Ç–≤–∞—á—ä—Ç –∏—Å–∫–∞ –¥–∞ –í–∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–µ—Ä—Ñ–µ–∫—Ç–Ω–∏—Ç–µ —Ä–µ—Ü–µ–ø—Ç–∏!")
st.caption("–ê–∫–æ –Ω–µ —Å—Ç–µ –¥–æ–≤–æ–ª–Ω–∏ –æ—Ç —Ä–µ—Ü–µ–ø—Ç–∞—Ç–∞, –º–æ–∂–µ –¥–∞ –∫–ª–∏–∫–Ω–µ—Ç–µ '–°—ä–∑–¥–∞–π —Ä–µ—Ü–µ–ø—Ç–∞' –ø–æ–≤—Ç–æ—Ä–Ω–æ - –ì–æ—Ç–≤–∞—á—ä—Ç —â–µ —Å–µ –æ–ø–∏—Ç–∞ –¥–∞ –∏–∑–º–∏—Å–ª–∏ –Ω–µ—â–æ –Ω–æ–≤–æ.")


if "ingredients" not in st.session_state:
    st.session_state.ingredients = []

if "recipe" not in st.session_state:
    st.session_state.recipe = ""

if "full_recipe" not in st.session_state:
    st.session_state.full_recipe = ""


# Generate recipes based on ingredients.
with st.expander("–°—ä–∑–¥–∞–π —Ä–µ—Ü–µ–ø—Ç–∞ –æ—Ç —Å—ä—Å—Ç–∞–≤–∫–∏"):
    ingredient = st.text_input('', placeholder="–í—ä–≤–µ–¥–∏ —Å—ä—Å—Ç–∞–≤–∫–∞")

    based_on_ingredients_widget(
        st, 
        ingredient=ingredient, 
        tokenizer=tokenizer, model=chef_gpt
    )

    ing_col1, ing_col2 = st.columns(2)

    # Ingredients subsection.
    with ing_col1:
        if st.session_state.ingredients:
            st.markdown("<h3 style='text-align: center; color: grey;'>–°—ä—Å—Ç–∞–≤–∫–∏</h3>", unsafe_allow_html=True)
            st.markdown(f"{', '.join(st.session_state.ingredients)}")

    # Recipe subsection.
    with ing_col2:
        if st.session_state.ingredients:
            st.markdown("<h3 style='text-align: center; color: grey;'>–†–µ—Ü–µ–ø—Ç–∞</h3>", unsafe_allow_html=True)
            
            if st.session_state.recipe:
                st.markdown(st.session_state.recipe)


with st.expander("–°—ä–∑–¥–∞–π —Ä–µ—Ü–µ–ø—Ç–∞ –æ—Ç –∏–º–µ"):
    title = st.text_input('', placeholder="–í—ä–≤–µ–¥–∏ –∏–º–µ –Ω–∞ —Ä–µ—Ü–µ–ø—Ç–∞—Ç–∞")

    based_on_title_widget(
        st, 
        title=title, 
        tokenizer=tokenizer, model=chef_gpt
    )

    if title:
        st.markdown("<h3 style='text-align: center; color: grey;'>–†–µ—Ü–µ–ø—Ç–∞</h3>", unsafe_allow_html=True)
        st.markdown(f"<h4 style='text-align: center; color: grey;'>{title}</h4>", unsafe_allow_html=True)
        
        if st.session_state.full_recipe:
            st.markdown(st.session_state.full_recipe)
